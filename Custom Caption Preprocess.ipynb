{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d51dc736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import h5py\n",
    "import itertools\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from config import Path\n",
    "from dictionary import Vocabulary\n",
    "from utils import Utils\n",
    "from evaluate import Evaluator\n",
    "from data import DataHandler\n",
    "\n",
    "utils = Utils()\n",
    "utils.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9efd4521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_words 1108 / 2191 = 0.5057\n",
      "Vocabulary Size :  1112\n"
     ]
    }
   ],
   "source": [
    "#Import configuration and model \n",
    "from config import ConfigSALSTM\n",
    "from models.SA_LSTM.model import SALSTM\n",
    "\n",
    "#create Mean pooling object\n",
    "cfg = ConfigSALSTM(opt_encoder=True)\n",
    "\n",
    "# specifying the dataset in configuration object from {'msvd','msrvtt'}\n",
    "cfg.dataset = 'msrvtt'\n",
    "\n",
    "#Changing the hyperparameters in configuration object\n",
    "cfg.batch_size = 32 #training batch size\n",
    "cfg.n_layers = 1    # number of layers in decoder rnn\n",
    "cfg.decoder_type = 'lstm'  # from {'lstm','gru'}\n",
    "cfg.dropout = 0.5\n",
    "cfg.opt_param_init = False\n",
    "\n",
    "#creation of path object\n",
    "path = Path(cfg, os.getcwd())\n",
    "\n",
    "#Vocabulary object, \n",
    "voc = Vocabulary(cfg)\n",
    "\n",
    "#If vocabulary is already saved or downloaded the saved file\n",
    "voc.load() #comment this if using vocabulary for the first time or with no saved file\n",
    "\n",
    "#If is not built\n",
    "# text_dict = {}\n",
    "# voc = Vocabulary(cfg)\n",
    "\n",
    "# text_dict.update(train_dict)\n",
    "# text_dict.update(val_dict)\n",
    "# text_dict.update(test_dict)\n",
    "\n",
    "# for k,v in text_dict.items():\n",
    "#     for anno in v:\n",
    "#         voc.addSentence(anno)\n",
    "        \n",
    "# voc.save()\n",
    "\n",
    "min_count = 2 #remove all words below count min_count\n",
    "voc.trim(min_count=min_count)\n",
    "\n",
    "print('Vocabulary Size : ',voc.num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75a340e",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbc4bcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets and dataloaders\n",
    "data_handler = DataHandler(cfg, path, voc)\n",
    "train_dset, val_dset, test_dset = data_handler.getDatasets()\n",
    "train_loader, val_loader, test_loader = data_handler.getDataloader(train_dset, val_dset, test_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cbb4d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "#Model object\n",
    "model = SALSTM(voc, cfg, path)\n",
    "\n",
    "#Evaluator object on test data\n",
    "test_evaluator_greedy = Evaluator(model, \n",
    "                                  test_loader,\n",
    "                                  path,cfg,\n",
    "                                  data_handler.test_dict)\n",
    "\n",
    "test_evaluator_beam = Evaluator(model,\n",
    "                                test_loader,\n",
    "                                path,\n",
    "                                cfg,\n",
    "                                data_handler.test_dict,\n",
    "                                decoding_type='beam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0920a266",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\GitHub\\SKRIPSI\\ORG-NACF\\ORG-NACF_Video-Captioning\\utils.py:80: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorAdvancedIndexing.cpp:1474.)\n",
      "  loss = crossEntropy.masked_select(mask).mean()\n",
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\autograd\\__init__.py:173: UserWarning: masked_scatter_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorAdvancedIndexing.cpp:1888.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "#Training Loop\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "cfg.encoder_lr = 1e-4\n",
    "cfg.decoder_lr = 1e-4\n",
    "cfg.teacher_forcing_ratio = 1.0\n",
    "model.update_hyperparameters(cfg)\n",
    "# lr_scheduler = ReduceLROnPlateau(model.dec_optimizer, mode='min', factor=cfg.lr_decay_gamma,\n",
    "#                                      patience=cfg.lr_decay_patience, verbose=True)\n",
    "\n",
    "for e in range(1,1351):\n",
    "    loss_train = model.train_epoch(train_loader, utils)\n",
    "    #loss_val = model.train_epoch(val_loader,utils)\n",
    "    #lr_scheduler.step(loss_train)\n",
    "    if e%50 == 0 :\n",
    "        print('Epoch -- >',e,'Loss -->',loss_train)\n",
    "        print('greedy :',test_evaluator_greedy.evaluate(utils,model,e,loss_train))\n",
    "        print('beam :',test_evaluator_beam.evaluate(utils,model,e,loss_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434b8de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_loader:\n",
    "    appearance_features, targets, mask, max_length, _, motion_features, _ = data\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0fdaca",
   "metadata": {},
   "source": [
    "# CAPTIONS\n",
    "\n",
    "* train_dict = {}\n",
    "* val_dict = {}\n",
    "* test_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e25619de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_msrvtt_path = \"MSRVTT\\\\captions\\\\train_val_videodatainfo.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84aaf47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_file = json.load(open(train_val_msrvtt_path))\n",
    "\n",
    "train_id_list = [i for i in range(0, 80)]\n",
    "val_id_list = [i for i in range(80, 90)]\n",
    "test_id_list = [i for i in range(90, 100)]\n",
    "\n",
    "train_dict = {}\n",
    "val_dict = {}\n",
    "test_dict = {}\n",
    "\n",
    "for datap in train_val_file['sentences']:\n",
    "    if int(datap['video_id'][5:]) in train_id_list:\n",
    "        if datap['video_id'] in list(train_dict.keys()):\n",
    "            train_dict[datap['video_id']] += [datap['caption']]\n",
    "        else:\n",
    "            train_dict[datap['video_id']] = [datap['caption']]\n",
    "    \n",
    "    if int(datap['video_id'][5:]) in val_id_list:\n",
    "        if datap['video_id'] in list(val_dict.keys()):\n",
    "            val_dict[datap['video_id']] += [datap['caption']]\n",
    "        else:\n",
    "            val_dict[datap['video_id']] = [datap['caption']]\n",
    "            \n",
    "    if int(datap['video_id'][5:]) in test_id_list:\n",
    "        if datap['video_id'] in list(test_dict.keys()):\n",
    "            test_dict[datap['video_id']] += [datap['caption']]\n",
    "        else:\n",
    "            test_dict[datap['video_id']] = [datap['caption']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10899e6",
   "metadata": {},
   "source": [
    "# FEATURES\n",
    "\n",
    "* Appearance Features\n",
    "* Motion Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97eb6455",
   "metadata": {},
   "outputs": [],
   "source": [
    "af_path = \"MSRVTT\\\\features\\\\image_inceptionresnetv2_imagenet_fps_max60_100.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85b210ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "appearance_feature_dict = {}\n",
    "\n",
    "f1 = h5py.File(af_path, 'r+')\n",
    "\n",
    "for key in f1.keys():\n",
    "    arr = f1[key]\n",
    "    \n",
    "    if arr.shape[0] < 28:\n",
    "        pad = self.cfg.frame_len - arr.shape[0]\n",
    "        arr = np.concatenate((arr,np.zeros((pad,arr.shape[1]))),axis = 0)\n",
    "    \n",
    "    appearance_feature_dict[key] = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3fb34e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_name_list = list(train_dict.keys())\n",
    "val_name_list = list(val_dict.keys())\n",
    "test_name_list = list(test_dict.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "4afee51a726235c094f63376612d0237ce82fa2ad7450f80d8972634d2ee05a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
